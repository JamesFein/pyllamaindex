[
    {
        "label": "runpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "runpy",
        "description": "runpy",
        "detail": "runpy",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "VectorStoreIndex",
        "importPath": "llama_index.core.indices",
        "description": "llama_index.core.indices",
        "isExtraImport": true,
        "detail": "llama_index.core.indices",
        "documentation": {}
    },
    {
        "label": "ChatRequest",
        "importPath": "llama_index.server.api.models",
        "description": "llama_index.server.api.models",
        "isExtraImport": true,
        "detail": "llama_index.server.api.models",
        "documentation": {}
    },
    {
        "label": "ChatRequest",
        "importPath": "llama_index.server.api.models",
        "description": "llama_index.server.api.models",
        "isExtraImport": true,
        "detail": "llama_index.server.api.models",
        "documentation": {}
    },
    {
        "label": "load_storage_context",
        "importPath": "app.storage_config",
        "description": "app.storage_config",
        "isExtraImport": true,
        "detail": "app.storage_config",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "llama_index.core",
        "description": "llama_index.core",
        "isExtraImport": true,
        "detail": "llama_index.core",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbedding",
        "importPath": "llama_index.embeddings.openai",
        "description": "llama_index.embeddings.openai",
        "isExtraImport": true,
        "detail": "llama_index.embeddings.openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "llama_index.llms.openai",
        "description": "llama_index.llms.openai",
        "isExtraImport": true,
        "detail": "llama_index.llms.openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "llama_index.llms.openai",
        "description": "llama_index.llms.openai",
        "isExtraImport": true,
        "detail": "llama_index.llms.openai",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "BaseDocumentStore",
        "importPath": "llama_index.core.storage.docstore.types",
        "description": "llama_index.core.storage.docstore.types",
        "isExtraImport": true,
        "detail": "llama_index.core.storage.docstore.types",
        "documentation": {}
    },
    {
        "label": "BaseIndexStore",
        "importPath": "llama_index.core.storage.index_store.types",
        "description": "llama_index.core.storage.index_store.types",
        "isExtraImport": true,
        "detail": "llama_index.core.storage.index_store.types",
        "documentation": {}
    },
    {
        "label": "BaseNode",
        "importPath": "llama_index.core.schema",
        "description": "llama_index.core.schema",
        "isExtraImport": true,
        "detail": "llama_index.core.schema",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "llama_index.core.schema",
        "description": "llama_index.core.schema",
        "isExtraImport": true,
        "detail": "llama_index.core.schema",
        "documentation": {}
    },
    {
        "label": "TextNode",
        "importPath": "llama_index.core.schema",
        "description": "llama_index.core.schema",
        "isExtraImport": true,
        "detail": "llama_index.core.schema",
        "documentation": {}
    },
    {
        "label": "IndexStruct",
        "importPath": "llama_index.core.data_structs.data_structs",
        "description": "llama_index.core.data_structs.data_structs",
        "isExtraImport": true,
        "detail": "llama_index.core.data_structs.data_structs",
        "documentation": {}
    },
    {
        "label": "StorageContext",
        "importPath": "llama_index.core.storage.storage_context",
        "description": "llama_index.core.storage.storage_context",
        "isExtraImport": true,
        "detail": "llama_index.core.storage.storage_context",
        "documentation": {}
    },
    {
        "label": "ChromaVectorStore",
        "importPath": "llama_index.vector_stores.chroma",
        "description": "llama_index.vector_stores.chroma",
        "isExtraImport": true,
        "detail": "llama_index.vector_stores.chroma",
        "documentation": {}
    },
    {
        "label": "chromadb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "chromadb",
        "description": "chromadb",
        "detail": "chromadb",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "chromadb.config",
        "description": "chromadb.config",
        "isExtraImport": true,
        "detail": "chromadb.config",
        "documentation": {}
    },
    {
        "label": "SQLiteDocumentStore",
        "importPath": "app.sqlite_stores",
        "description": "app.sqlite_stores",
        "isExtraImport": true,
        "detail": "app.sqlite_stores",
        "documentation": {}
    },
    {
        "label": "SQLiteIndexStore",
        "importPath": "app.sqlite_stores",
        "description": "app.sqlite_stores",
        "isExtraImport": true,
        "detail": "app.sqlite_stores",
        "documentation": {}
    },
    {
        "label": "get_index",
        "importPath": "app.index",
        "description": "app.index",
        "isExtraImport": true,
        "detail": "app.index",
        "documentation": {}
    },
    {
        "label": "get_index",
        "importPath": "app.index",
        "description": "app.index",
        "isExtraImport": true,
        "detail": "app.index",
        "documentation": {}
    },
    {
        "label": "AgentWorkflow",
        "importPath": "llama_index.core.agent.workflow",
        "description": "llama_index.core.agent.workflow",
        "isExtraImport": true,
        "detail": "llama_index.core.agent.workflow",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "llama_index.core.settings",
        "description": "llama_index.core.settings",
        "isExtraImport": true,
        "detail": "llama_index.core.settings",
        "documentation": {}
    },
    {
        "label": "get_query_engine_tool",
        "importPath": "llama_index.server.tools.index",
        "description": "llama_index.server.tools.index",
        "isExtraImport": true,
        "detail": "llama_index.server.tools.index",
        "documentation": {}
    },
    {
        "label": "CITATION_SYSTEM_PROMPT",
        "importPath": "llama_index.server.tools.index.citation",
        "description": "llama_index.server.tools.index.citation",
        "isExtraImport": true,
        "detail": "llama_index.server.tools.index.citation",
        "documentation": {}
    },
    {
        "label": "enable_citation",
        "importPath": "llama_index.server.tools.index.citation",
        "description": "llama_index.server.tools.index.citation",
        "isExtraImport": true,
        "detail": "llama_index.server.tools.index.citation",
        "documentation": {}
    },
    {
        "label": "TTFont",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "sfnt",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "TTFont",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "timestampNow",
        "importPath": "fontTools.misc.timeTools",
        "description": "fontTools.misc.timeTools",
        "isExtraImport": true,
        "detail": "fontTools.misc.timeTools",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "parse_tfm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "parse_tfm",
        "description": "parse_tfm",
        "detail": "parse_tfm",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "init_settings",
        "importPath": "app.settings",
        "description": "app.settings",
        "isExtraImport": true,
        "detail": "app.settings",
        "documentation": {}
    },
    {
        "label": "create_workflow",
        "importPath": "app.workflow",
        "description": "app.workflow",
        "isExtraImport": true,
        "detail": "app.workflow",
        "documentation": {}
    },
    {
        "label": "LlamaIndexServer",
        "importPath": "llama_index.server",
        "description": "llama_index.server",
        "isExtraImport": true,
        "detail": "llama_index.server",
        "documentation": {}
    },
    {
        "label": "UIConfig",
        "importPath": "llama_index.server",
        "description": "llama_index.server",
        "isExtraImport": true,
        "detail": "llama_index.server",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StaticFiles",
        "importPath": "fastapi.staticfiles",
        "description": "fastapi.staticfiles",
        "isExtraImport": true,
        "detail": "fastapi.staticfiles",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"Scripts\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"app\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"Scripts\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"app\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"app\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"app\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV_PROMPT\"]",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV_PROMPT\"] = \"app\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"..\\\\Lib\\\\site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": ".venv.Scripts.activate_this",
        "description": ".venv.Scripts.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": ".venv.Scripts.activate_this",
        "documentation": {}
    },
    {
        "label": "get_index",
        "kind": 2,
        "importPath": "app.index",
        "description": "app.index",
        "peekOfCode": "def get_index(chat_request: Optional[ChatRequest] = None):\n    # check if storage already exists\n    if not os.path.exists(STORAGE_DIR):\n        return None\n    # load the existing storage context with SQLite and ChromaDB\n    logger.info(f\"Loading index from {STORAGE_DIR} using SQLite and ChromaDB...\")\n    storage_context = load_storage_context(STORAGE_DIR)\n    if storage_context is None:\n        logger.warning(f\"Could not load storage context from {STORAGE_DIR}\")\n        return None",
        "detail": "app.index",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.index",
        "description": "app.index",
        "peekOfCode": "logger = logging.getLogger(\"uvicorn\")\nSTORAGE_DIR = \"storage\"\ndef get_index(chat_request: Optional[ChatRequest] = None):\n    # check if storage already exists\n    if not os.path.exists(STORAGE_DIR):\n        return None\n    # load the existing storage context with SQLite and ChromaDB\n    logger.info(f\"Loading index from {STORAGE_DIR} using SQLite and ChromaDB...\")\n    storage_context = load_storage_context(STORAGE_DIR)\n    if storage_context is None:",
        "detail": "app.index",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "kind": 5,
        "importPath": "app.index",
        "description": "app.index",
        "peekOfCode": "STORAGE_DIR = \"storage\"\ndef get_index(chat_request: Optional[ChatRequest] = None):\n    # check if storage already exists\n    if not os.path.exists(STORAGE_DIR):\n        return None\n    # load the existing storage context with SQLite and ChromaDB\n    logger.info(f\"Loading index from {STORAGE_DIR} using SQLite and ChromaDB...\")\n    storage_context = load_storage_context(STORAGE_DIR)\n    if storage_context is None:\n        logger.warning(f\"Could not load storage context from {STORAGE_DIR}\")",
        "detail": "app.index",
        "documentation": {}
    },
    {
        "label": "init_settings",
        "kind": 2,
        "importPath": "app.settings",
        "description": "app.settings",
        "peekOfCode": "def init_settings():\n    if os.getenv(\"OPENAI_API_KEY\") is None:\n        raise RuntimeError(\"OPENAI_API_KEY is missing in environment variables\")\n    Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n    Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")",
        "detail": "app.settings",
        "documentation": {}
    },
    {
        "label": "SQLiteDocumentStore",
        "kind": 6,
        "importPath": "app.sqlite_stores",
        "description": "app.sqlite_stores",
        "peekOfCode": "class SQLiteDocumentStore(BaseDocumentStore):\n    \"\"\"SQLite-based document store for better performance and concurrency.\"\"\"\n    def __init__(self, db_path: str):\n        \"\"\"Initialize SQLite document store.\n        Args:\n            db_path: Path to SQLite database file\n        \"\"\"\n        self.db_path = db_path\n        logger.info(f\"🔥 Initializing SQLiteDocumentStore at {db_path}\")\n        self._init_db()",
        "detail": "app.sqlite_stores",
        "documentation": {}
    },
    {
        "label": "SQLiteIndexStore",
        "kind": 6,
        "importPath": "app.sqlite_stores",
        "description": "app.sqlite_stores",
        "peekOfCode": "class SQLiteIndexStore(BaseIndexStore):\n    \"\"\"SQLite-based index store for better performance and concurrency.\"\"\"\n    def __init__(self, db_path: str):\n        \"\"\"Initialize SQLite index store.\n        Args:\n            db_path: Path to SQLite database file\n        \"\"\"\n        self.db_path = db_path\n        self._init_db()\n    def _init_db(self):",
        "detail": "app.sqlite_stores",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.sqlite_stores",
        "description": "app.sqlite_stores",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass SQLiteDocumentStore(BaseDocumentStore):\n    \"\"\"SQLite-based document store for better performance and concurrency.\"\"\"\n    def __init__(self, db_path: str):\n        \"\"\"Initialize SQLite document store.\n        Args:\n            db_path: Path to SQLite database file\n        \"\"\"\n        self.db_path = db_path\n        logger.info(f\"🔥 Initializing SQLiteDocumentStore at {db_path}\")",
        "detail": "app.sqlite_stores",
        "documentation": {}
    },
    {
        "label": "get_storage_context",
        "kind": 2,
        "importPath": "app.storage_config",
        "description": "app.storage_config",
        "peekOfCode": "def get_storage_context(storage_dir: str = \"storage\") -> StorageContext:\n    \"\"\"\n    Create a storage context using SQLite for docstore/index store and ChromaDB for vector store.\n    Args:\n        storage_dir: Directory to store the databases\n    Returns:\n        StorageContext configured with SQLite and ChromaDB backends\n    \"\"\"\n    # Ensure storage directory exists\n    os.makedirs(storage_dir, exist_ok=True)",
        "detail": "app.storage_config",
        "documentation": {}
    },
    {
        "label": "load_storage_context",
        "kind": 2,
        "importPath": "app.storage_config",
        "description": "app.storage_config",
        "peekOfCode": "def load_storage_context(storage_dir: str = \"storage\") -> Optional[StorageContext]:\n    \"\"\"\n    Load existing storage context from ChromaDB and SQLite stores.\n    Args:\n        storage_dir: Directory containing the databases\n    Returns:\n        StorageContext if databases exist, None otherwise\n    \"\"\"\n    # Check if storage directory exists\n    if not os.path.exists(storage_dir):",
        "detail": "app.storage_config",
        "documentation": {}
    },
    {
        "label": "migrate_json_to_sqlite",
        "kind": 2,
        "importPath": "app.storage_config",
        "description": "app.storage_config",
        "peekOfCode": "def migrate_json_to_sqlite(storage_dir: str = \"storage\") -> bool:\n    \"\"\"\n    Migrate existing JSON storage to SQLite.\n    Args:\n        storage_dir: Directory containing the storage files\n    Returns:\n        True if migration was successful, False otherwise\n    \"\"\"\n    import json\n    import sqlite3",
        "detail": "app.storage_config",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.storage_config",
        "description": "app.storage_config",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef get_storage_context(storage_dir: str = \"storage\") -> StorageContext:\n    \"\"\"\n    Create a storage context using SQLite for docstore/index store and ChromaDB for vector store.\n    Args:\n        storage_dir: Directory to store the databases\n    Returns:\n        StorageContext configured with SQLite and ChromaDB backends\n    \"\"\"\n    # Ensure storage directory exists",
        "detail": "app.storage_config",
        "documentation": {}
    },
    {
        "label": "create_workflow",
        "kind": 2,
        "importPath": "app.workflow",
        "description": "app.workflow",
        "peekOfCode": "def create_workflow(chat_request: Optional[ChatRequest] = None) -> AgentWorkflow:\n    index = get_index(chat_request=chat_request)\n    if index is None:\n        raise RuntimeError(\n            \"Index not found! Please run `uv run generate` to index the data first.\"\n        )\n    # Create a query tool with citations enabled\n    query_tool = enable_citation(get_query_engine_tool(index=index))\n    # Define the system prompt for the agent\n    # Append the citation system prompt to the system prompt",
        "detail": "app.workflow",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "components.node_modules.flatted.python.flatted",
        "description": "components.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "components.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "components.node_modules.flatted.python.flatted",
        "description": "components.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "components.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "components.node_modules.flatted.python.flatted",
        "description": "components.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "components.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "components.node_modules.flatted.python.flatted",
        "description": "components.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "components.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "sfnt.USE_ZOPFLI",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "sfnt.USE_ZOPFLI = True\nif len(sys.argv) < 2:\n    print(\"Usage: %s <font file>\" % sys.argv[0])\n    sys.exit(1)\nfont_file = sys.argv[1]\nfont_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font_file",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font_file = sys.argv[1]\nfont_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font_name",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['head'].created",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']\n# remove Macintosh table\n# https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6cmap.html",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['head'].modified",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']\n# remove Macintosh table\n# https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6cmap.html\nfont['name'].names = [record for record in font['name'].names if record.platformID != 1]",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['name'].names",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['name'].names = [record for record in font['name'].names if record.platformID != 1]\nfont['cmap'].tables = [table for table in font['cmap'].tables if table.platformID != 1]\n# fix OS/2 and hhea metrics\nglyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['cmap'].tables",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['cmap'].tables = [table for table in font['cmap'].tables if table.platformID != 1]\n# fix OS/2 and hhea metrics\nglyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "glyf",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "glyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "ascent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "ascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "descent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "descent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['OS/2'].usWinAscent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['OS/2'].usWinDescent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['hhea'].ascent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['hhea'].descent",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font.flavor",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font.flavor",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.fonts.generate_fonts",
        "description": "components.node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "components.node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "find_font_path",
        "kind": 2,
        "importPath": "components.node_modules.katex.src.metrics.extract_tfms",
        "description": "components.node_modules.katex.src.metrics.extract_tfms",
        "peekOfCode": "def find_font_path(font_name):\n    try:\n        font_path = subprocess.check_output(['kpsewhich', font_name])\n    except OSError:\n        raise RuntimeError(\"Couldn't find kpsewhich program, make sure you\" +\n                           \" have TeX installed\")\n    except subprocess.CalledProcessError:\n        raise RuntimeError(\"Couldn't find font metrics: '%s'\" % font_name)\n    return font_path.strip()\ndef main():",
        "detail": "components.node_modules.katex.src.metrics.extract_tfms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "components.node_modules.katex.src.metrics.extract_tfms",
        "description": "components.node_modules.katex.src.metrics.extract_tfms",
        "peekOfCode": "def main():\n    mapping = json.load(sys.stdin)\n    fonts = [\n        'cmbsy10.tfm',\n        'cmbx10.tfm',\n        'cmbxti10.tfm',\n        'cmex10.tfm',\n        'cmmi10.tfm',\n        'cmmib10.tfm',\n        'cmr10.tfm',",
        "detail": "components.node_modules.katex.src.metrics.extract_tfms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "components.node_modules.katex.src.metrics.extract_ttfs",
        "description": "components.node_modules.katex.src.metrics.extract_ttfs",
        "peekOfCode": "def main():\n    start_json = json.load(sys.stdin)\n    for font in start_json:\n        fontInfo = TTFont(\"../../fonts/KaTeX_\" + font + \".ttf\")\n        glyf = fontInfo[\"glyf\"]\n        widths = fontInfo.getGlyphSet()\n        unitsPerEm = float(fontInfo[\"head\"].unitsPerEm)\n        # We keep ALL Unicode cmaps, not just fontInfo[\"cmap\"].getcmap(3, 1).\n        # This is playing it extra safe, since it reports inconsistencies.\n        # Platform 0 is Unicode, platform 3 is Windows. For platform 3,",
        "detail": "components.node_modules.katex.src.metrics.extract_ttfs",
        "documentation": {}
    },
    {
        "label": "metrics_to_extract",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.metrics.extract_ttfs",
        "description": "components.node_modules.katex.src.metrics.extract_ttfs",
        "peekOfCode": "metrics_to_extract = {\n    # Font name\n    \"AMS-Regular\": {\n        u\"\\u21e2\": None,  # \\dashrightarrow\n        u\"\\u21e0\": None,  # \\dashleftarrow\n    },\n    \"Main-Regular\": {\n        # Skew and italic metrics can't be easily parsed from the TTF. Instead,\n        # we map each character to a \"base character\", which is a character\n        # from the same font with correct italic and skew metrics. A character",
        "detail": "components.node_modules.katex.src.metrics.extract_ttfs",
        "documentation": {}
    },
    {
        "label": "props",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.metrics.format_json",
        "description": "components.node_modules.katex.src.metrics.format_json",
        "peekOfCode": "props = ['depth', 'height', 'italic', 'skew']\nif len(sys.argv) > 1:\n    if sys.argv[1] == '--width':\n        props.append('width')\ndata = json.load(sys.stdin)\nsys.stdout.write(\n  \"// This file is GENERATED by buildMetrics.sh. DO NOT MODIFY.\\n\")\nsep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))",
        "detail": "components.node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.metrics.format_json",
        "description": "components.node_modules.katex.src.metrics.format_json",
        "peekOfCode": "data = json.load(sys.stdin)\nsys.stdout.write(\n  \"// This file is GENERATED by buildMetrics.sh. DO NOT MODIFY.\\n\")\nsep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))\n    sep = \": {\\n        \"\n    for glyph in sorted(data[font], key=int):\n        sys.stdout.write(sep + json.dumps(glyph) + \": \")\n        values = [value if value != 0.0 else 0 for value in",
        "detail": "components.node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "sep",
        "kind": 5,
        "importPath": "components.node_modules.katex.src.metrics.format_json",
        "description": "components.node_modules.katex.src.metrics.format_json",
        "peekOfCode": "sep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))\n    sep = \": {\\n        \"\n    for glyph in sorted(data[font], key=int):\n        sys.stdout.write(sep + json.dumps(glyph) + \": \")\n        values = [value if value != 0.0 else 0 for value in\n                  [data[font][glyph][key] for key in props]]\n        sys.stdout.write(json.dumps(values))\n        sep = \",\\n        \"",
        "detail": "components.node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "CharInfoWord",
        "kind": 6,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class CharInfoWord(object):\n    def __init__(self, word):\n        b1, b2, b3, b4 = (word >> 24,\n                          (word & 0xff0000) >> 16,\n                          (word & 0xff00) >> 8,\n                          word & 0xff)\n        self.width_index = b1\n        self.height_index = b2 >> 4\n        self.depth_index = b2 & 0x0f\n        self.italic_index = (b3 & 0b11111100) >> 2",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "LigKernProgram",
        "kind": 6,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class LigKernProgram(object):\n    def __init__(self, program):\n        self.program = program\n    def execute(self, start, next_char):\n        curr_instruction = start\n        while True:\n            instruction = self.program[curr_instruction]\n            (skip, inst_next_char, op, remainder) = instruction\n            if inst_next_char == next_char:\n                if op < 128:",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmCharMetrics",
        "kind": 6,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmCharMetrics(object):\n    def __init__(self, width, height, depth, italic, kern_table):\n        self.width = width\n        self.height = height\n        self.depth = depth\n        self.italic_correction = italic\n        self.kern_table = kern_table\nclass TfmFile(object):\n    def __init__(self, start_char, end_char, char_info, width_table,\n                 height_table, depth_table, italic_table, ligkern_table,",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmFile",
        "kind": 6,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmFile(object):\n    def __init__(self, start_char, end_char, char_info, width_table,\n                 height_table, depth_table, italic_table, ligkern_table,\n                 kern_table):\n        self.start_char = start_char\n        self.end_char = end_char\n        self.char_info = char_info\n        self.width_table = width_table\n        self.height_table = height_table\n        self.depth_table = depth_table",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmReader",
        "kind": 6,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmReader(object):\n    def __init__(self, f):\n        self.f = f\n    def read_byte(self):\n        return ord(self.f.read(1))\n    def read_halfword(self):\n        b1 = self.read_byte()\n        b2 = self.read_byte()\n        return (b1 << 8) | b2\n    def read_word(self):",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "read_tfm_file",
        "kind": 2,
        "importPath": "components.node_modules.katex.src.metrics.parse_tfm",
        "description": "components.node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "def read_tfm_file(file_name):\n    with open(file_name, 'rb') as f:\n        reader = TfmReader(f)\n        # file_size\n        reader.read_halfword()\n        header_size = reader.read_halfword()\n        start_char = reader.read_halfword()\n        end_char = reader.read_halfword()\n        width_table_size = reader.read_halfword()\n        height_table_size = reader.read_halfword()",
        "detail": "components.node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "generate_index",
        "kind": 2,
        "importPath": "generate",
        "description": "generate",
        "peekOfCode": "def generate_index():\n    \"\"\"\n    Index the documents in the data directory using SQLite and ChromaDB.\n    \"\"\"\n    from app.index import STORAGE_DIR\n    from app.settings import init_settings\n    from app.storage_config import get_storage_context\n    from llama_index.core.indices import (\n        VectorStoreIndex,\n    )",
        "detail": "generate",
        "documentation": {}
    },
    {
        "label": "generate_ui_for_workflow",
        "kind": 2,
        "importPath": "generate",
        "description": "generate",
        "peekOfCode": "def generate_ui_for_workflow():\n    \"\"\"\n    Generate UI for UIEventData event in app/workflow.py\n    \"\"\"\n    import asyncio\n    from main import COMPONENT_DIR\n    # To generate UI components for additional event types,\n    # import the corresponding data model (e.g., MyCustomEventData)\n    # and run the generate_ui_for_workflow function with the imported model.\n    # Make sure the output filename of the generated UI component matches the event type (here `ui_event`)",
        "detail": "generate",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "generate",
        "description": "generate",
        "peekOfCode": "logger = logging.getLogger()\ndef generate_index():\n    \"\"\"\n    Index the documents in the data directory using SQLite and ChromaDB.\n    \"\"\"\n    from app.index import STORAGE_DIR\n    from app.settings import init_settings\n    from app.storage_config import get_storage_context\n    from llama_index.core.indices import (\n        VectorStoreIndex,",
        "detail": "generate",
        "documentation": {}
    },
    {
        "label": "create_app",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def create_app():\n    app = LlamaIndexServer(\n        workflow_factory=create_workflow,  # A factory function that creates a new workflow for each request\n        ui_config=UIConfig(\n            enabled=False,  # 禁用默认UI\n        ),\n        logger=logger,\n        env=\"dev\",\n    )\n    # 添加CORS中间件",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "logger = logging.getLogger(\"uvicorn\")\n# A path to a directory where the customized UI code is stored\nCOMPONENT_DIR = \"components\"\ndef create_app():\n    app = LlamaIndexServer(\n        workflow_factory=create_workflow,  # A factory function that creates a new workflow for each request\n        ui_config=UIConfig(\n            enabled=False,  # 禁用默认UI\n        ),\n        logger=logger,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "COMPONENT_DIR",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "COMPONENT_DIR = \"components\"\ndef create_app():\n    app = LlamaIndexServer(\n        workflow_factory=create_workflow,  # A factory function that creates a new workflow for each request\n        ui_config=UIConfig(\n            enabled=False,  # 禁用默认UI\n        ),\n        logger=logger,\n        env=\"dev\",\n    )",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = create_app()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "migrate_database",
        "kind": 2,
        "importPath": "migrate_db",
        "description": "migrate_db",
        "peekOfCode": "def migrate_database():\n    \"\"\"Migrate the database to add new columns.\"\"\"\n    db_path = \"storage/docstore.db\"\n    if not os.path.exists(db_path):\n        logger.error(f\"Database file not found: {db_path}\")\n        return False\n    try:\n        with sqlite3.connect(db_path) as conn:\n            # Check current schema\n            cursor = conn.execute(\"PRAGMA table_info(documents)\")",
        "detail": "migrate_db",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "migrate_db",
        "description": "migrate_db",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef migrate_database():\n    \"\"\"Migrate the database to add new columns.\"\"\"\n    db_path = \"storage/docstore.db\"\n    if not os.path.exists(db_path):\n        logger.error(f\"Database file not found: {db_path}\")\n        return False\n    try:\n        with sqlite3.connect(db_path) as conn:\n            # Check current schema",
        "detail": "migrate_db",
        "documentation": {}
    },
    {
        "label": "calculate_file_hash",
        "kind": 2,
        "importPath": "migrate_to_file_management",
        "description": "migrate_to_file_management",
        "peekOfCode": "def calculate_file_hash(file_path: str) -> str:\n    \"\"\"计算文件的MD5哈希值\"\"\"\n    hash_md5 = hashlib.md5()\n    try:\n        with open(file_path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n    except Exception as e:\n        logger.warning(f\"Failed to calculate hash for {file_path}: {e}\")",
        "detail": "migrate_to_file_management",
        "documentation": {}
    },
    {
        "label": "migrate_database",
        "kind": 2,
        "importPath": "migrate_to_file_management",
        "description": "migrate_to_file_management",
        "peekOfCode": "def migrate_database():\n    \"\"\"执行数据库迁移\"\"\"\n    db_path = \"storage/docstore.db\"\n    data_dir = \"data\"\n    if not os.path.exists(db_path):\n        logger.error(f\"Database file not found: {db_path}\")\n        return False\n    if not os.path.exists(data_dir):\n        logger.error(f\"Data directory not found: {data_dir}\")\n        return False",
        "detail": "migrate_to_file_management",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "migrate_to_file_management",
        "description": "migrate_to_file_management",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef calculate_file_hash(file_path: str) -> str:\n    \"\"\"计算文件的MD5哈希值\"\"\"\n    hash_md5 = hashlib.md5()\n    try:\n        with open(file_path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n    except Exception as e:",
        "detail": "migrate_to_file_management",
        "documentation": {}
    },
    {
        "label": "update_file_metadata",
        "kind": 2,
        "importPath": "update_file_metadata",
        "description": "update_file_metadata",
        "peekOfCode": "def update_file_metadata():\n    \"\"\"Update existing documents with file metadata.\"\"\"\n    db_path = \"storage/docstore.db\"\n    data_dir = \"data\"\n    if not os.path.exists(db_path):\n        logger.error(f\"Database file not found: {db_path}\")\n        return False\n    if not os.path.exists(data_dir):\n        logger.error(f\"Data directory not found: {data_dir}\")\n        return False",
        "detail": "update_file_metadata",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "update_file_metadata",
        "description": "update_file_metadata",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef update_file_metadata():\n    \"\"\"Update existing documents with file metadata.\"\"\"\n    db_path = \"storage/docstore.db\"\n    data_dir = \"data\"\n    if not os.path.exists(db_path):\n        logger.error(f\"Database file not found: {db_path}\")\n        return False\n    if not os.path.exists(data_dir):\n        logger.error(f\"Data directory not found: {data_dir}\")",
        "detail": "update_file_metadata",
        "documentation": {}
    }
]
#!/usr/bin/env python3
"""
åˆ†æå­˜å‚¨ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
"""
import sqlite3
import json
import os
from pathlib import Path

def analyze_storage_directory():
    """åˆ†æå­˜å‚¨ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    storage_dir = Path("storage")
    
    print("ğŸ“ å­˜å‚¨ç›®å½•åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # 1. åˆ†ææ‰€æœ‰æ–‡ä»¶
    print("ğŸ“‹ æ–‡ä»¶æ¸…å•:")
    for file_path in storage_dir.rglob("*"):
        if file_path.is_file():
            size = file_path.stat().st_size
            print(f"  - {file_path.relative_to(storage_dir)}: {size:,} bytes")
    print()
    
    # 2. åˆ†æSQLiteæ•°æ®åº“
    sqlite_files = [
        "docstore.db",
        "index_store.db", 
        "chroma_db/chroma.sqlite3"
    ]
    
    for db_file in sqlite_files:
        db_path = storage_dir / db_file
        if db_path.exists():
            print(f"ğŸ—„ï¸  åˆ†æ {db_file}:")
            analyze_sqlite_db(db_path)
            print()
    
    # 3. åˆ†æJSONæ–‡ä»¶
    json_files = [
        "graph_store.json",
        "image__vector_store.json"
    ]
    
    for json_file in json_files:
        json_path = storage_dir / json_file
        if json_path.exists():
            print(f"ğŸ“„ åˆ†æ {json_file}:")
            analyze_json_file(json_path)
            print()

def analyze_sqlite_db(db_path):
    """åˆ†æSQLiteæ•°æ®åº“"""
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # è·å–è¡¨åˆ—è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            print(f"    è¡¨æ•°é‡: {len(tables)}")
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                
                # è·å–è¡¨ç»“æ„
                cursor.execute(f"PRAGMA table_info({table})")
                columns = cursor.fetchall()
                
                print(f"    - {table}: {count:,} è¡Œ, {len(columns)} åˆ—")
                
                # æ˜¾ç¤ºåˆ—ä¿¡æ¯
                for col in columns[:5]:  # åªæ˜¾ç¤ºå‰5åˆ—
                    print(f"      * {col[1]} ({col[2]})")
                if len(columns) > 5:
                    print(f"      ... è¿˜æœ‰ {len(columns) - 5} åˆ—")
                
                # å¦‚æœæœ‰æ•°æ®ï¼Œæ˜¾ç¤ºä¸€äº›æ ·æœ¬
                if count > 0 and count < 1000:  # åªå¯¹å°è¡¨æ˜¾ç¤ºæ ·æœ¬
                    cursor.execute(f"SELECT * FROM {table} LIMIT 3")
                    samples = cursor.fetchall()
                    if samples:
                        print(f"      æ ·æœ¬æ•°æ®: {len(samples)} è¡Œ")
                        for i, sample in enumerate(samples):
                            # åªæ˜¾ç¤ºå‰3ä¸ªå­—æ®µï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                            sample_str = str(sample[:3])
                            if len(sample_str) > 100:
                                sample_str = sample_str[:100] + "..."
                            print(f"        [{i+1}] {sample_str}")
                
    except Exception as e:
        print(f"    âŒ é”™è¯¯: {e}")

def analyze_json_file(json_path):
    """åˆ†æJSONæ–‡ä»¶"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"    æ–‡ä»¶å¤§å°: {json_path.stat().st_size:,} bytes")
        print(f"    JSONç»“æ„:")
        
        def analyze_json_structure(obj, indent=6):
            if isinstance(obj, dict):
                print(f"{' ' * indent}å­—å…¸ - {len(obj)} ä¸ªé”®:")
                for key, value in list(obj.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”®
                    print(f"{' ' * (indent+2)}- {key}: {type(value).__name__}")
                    if isinstance(value, (dict, list)) and len(str(value)) < 200:
                        analyze_json_structure(value, indent + 4)
                if len(obj) > 5:
                    print(f"{' ' * (indent+2)}... è¿˜æœ‰ {len(obj) - 5} ä¸ªé”®")
            elif isinstance(obj, list):
                print(f"{' ' * indent}åˆ—è¡¨ - {len(obj)} ä¸ªå…ƒç´ ")
                if obj and len(obj) <= 3:
                    for i, item in enumerate(obj):
                        print(f"{' ' * (indent+2)}[{i}]: {type(item).__name__}")
            else:
                value_str = str(obj)
                if len(value_str) > 50:
                    value_str = value_str[:50] + "..."
                print(f"{' ' * indent}å€¼: {value_str}")
        
        analyze_json_structure(data)
        
    except Exception as e:
        print(f"    âŒ é”™è¯¯: {e}")

def check_file_usage():
    """æ£€æŸ¥æ–‡ä»¶çš„å®é™…ä½¿ç”¨æƒ…å†µ"""
    print("ğŸ” æ–‡ä»¶ä½¿ç”¨æƒ…å†µåˆ†æ:")
    print("=" * 60)
    
    # æ£€æŸ¥ä»£ç ä¸­å¯¹è¿™äº›æ–‡ä»¶çš„å¼•ç”¨
    storage_files = [
        "docstore.db",
        "index_store.db", 
        "chroma.sqlite3",
        "graph_store.json",
        "image__vector_store.json"
    ]
    
    for file_name in storage_files:
        print(f"ğŸ“„ {file_name}:")
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä»£ç æ¥æœç´¢æ–‡ä»¶å¼•ç”¨
        # ä½†ç”±äºæˆ‘ä»¬åœ¨åˆ†æè„šæœ¬ä¸­ï¼Œå…ˆæ‰‹åŠ¨åˆ†æ
        if "graph_store" in file_name:
            print("    - ç”¨é€”: å›¾å­˜å‚¨ï¼ˆçŸ¥è¯†å›¾è°±ï¼‰")
            print("    - é¡¹ç›®éœ€è¦: âŒ ä»…å¤„ç†txtæ–‡ä»¶ï¼Œä¸éœ€è¦å›¾ç»“æ„")
        elif "image" in file_name:
            print("    - ç”¨é€”: å›¾åƒå‘é‡å­˜å‚¨")
            print("    - é¡¹ç›®éœ€è¦: âŒ ä»…å¤„ç†txtæ–‡ä»¶ï¼Œä¸å¤„ç†å›¾åƒ")
        elif "chroma" in file_name:
            print("    - ç”¨é€”: ChromaDBå‘é‡æ•°æ®åº“")
            print("    - é¡¹ç›®éœ€è¦: âœ… ç”¨äºæ–‡æœ¬å‘é‡å­˜å‚¨å’Œæ£€ç´¢")
        elif "docstore" in file_name:
            print("    - ç”¨é€”: æ–‡æ¡£å­˜å‚¨")
            print("    - é¡¹ç›®éœ€è¦: âœ… å­˜å‚¨æ–‡æ¡£å’Œæ–‡æœ¬å—")
        elif "index_store" in file_name:
            print("    - ç”¨é€”: ç´¢å¼•ç»“æ„å­˜å‚¨")
            print("    - é¡¹ç›®éœ€è¦: âœ… å­˜å‚¨ç´¢å¼•å…ƒæ•°æ®")
        print()

if __name__ == "__main__":
    analyze_storage_directory()
    check_file_usage()
